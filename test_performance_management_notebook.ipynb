{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\r\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\r\n",
      "Collecting torch\r\n",
      "  Using cached torch-2.6.0-cp39-none-macosx_11_0_arm64.whl (66.5 MB)\r\n",
      "Collecting safetensors>=0.4.1\r\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m418.4/418.4 kB\u001B[0m \u001B[31m14.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting filelock\r\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Collecting huggingface-hub<1.0,>=0.26.0\r\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m469.0/469.0 kB\u001B[0m \u001B[31m15.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting tokenizers<0.22,>=0.21\r\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.7/2.7 MB\u001B[0m \u001B[31m50.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting tqdm>=4.27\r\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.9/site-packages (from transformers) (2.0.2)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from transformers) (2.32.3)\r\n",
      "Collecting regex!=2019.12.17\r\n",
      "  Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from transformers) (24.2)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch) (3.1.5)\r\n",
      "Collecting fsspec\r\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m193.6/193.6 kB\u001B[0m \u001B[31m25.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.9/site-packages (from torch) (4.12.2)\r\n",
      "Collecting sympy==1.13.1\r\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch) (3.2.1)\r\n",
      "Collecting mpmath<1.4,>=1.1.0\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->transformers) (2025.1.31)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->transformers) (2.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->transformers) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->transformers) (3.10)\r\n",
      "Installing collected packages: mpmath, tqdm, sympy, safetensors, regex, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers\r\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.0 huggingface-hub-0.29.3 mpmath-1.3.0 regex-2024.11.6 safetensors-0.5.3 sympy-1.13.1 tokenizers-0.21.1 torch-2.6.0 tqdm-4.67.1 transformers-4.49.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T18:07:32.451708Z",
     "start_time": "2025-03-14T18:07:16.011944Z"
    }
   },
   "id": "15b5683d8f18ffd0"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuacolston/PycharmProjects/enronProject/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the BART summarization model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T18:09:03.849291Z",
     "start_time": "2025-03-14T18:08:47.250118Z"
    }
   },
   "id": "f74933e87a6237e7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Led the development and deployment of an AI-powered recommendation system that increased user engagement by 35%.\n",
      "- Spearheaded the migration of legacy systems to a cloud-based infrastructure, reducing operational costs by 20%.\n",
      "- Designed and implemented a real-time fraud detection algorithm, improving security and reducing false positives by 40%.\n",
      "- Published multiple research papers on machine learning and NLP in top-tier conferences such as NeurIPS and ICML.\n",
      "- Successfully managed a cross-functional team of engineers, data scientists, and product managers to deliver a high-impact project ahead of schedule.\n",
      "- Optimized database queries and indexing strategies, reducing query response time by 50%.\n",
      "- Developed and launched a company-wide innovation board, fostering knowledge sharing and increasing engineering velocity.\n",
      "- Contributed to open-source projects in the cybersecurity and machine learning communities, gaining over 10,000 GitHub stars.\n",
      "- Implemented a CI/CD pipeline, reducing deployment times from hours to minutes and improving system reliability.\n",
      "- Conducted in-depth bias analysis on machine learning models, implementing fairness adjustments to ensure ethical AI practices.\n",
      "- Improved search ranking algorithms, increasing click-through rates by 25% through advanced NLP techniques.\n",
      "- Designed and taught a machine learning course, mentoring over 200 students and professionals in AI applications.\n",
      "- Created an automated data pipeline that processed millions of records daily, improving data integrity and accuracy.\n",
      "- Received multiple performance awards for outstanding contributions in engineering and innovation.\n",
      "- Developed a predictive analytics tool that improved customer retention rates by 30%.\n",
      "- Presented at international conferences and industry panels on AI ethics and responsible data practices.\n",
      "- Led security audits and vulnerability assessments, strengthening cybersecurity defenses across the organization.\n",
      "- Designed a scalable architecture for a fintech application, handling millions of transactions per second.\n",
      "- Built a personalized chatbot assistant that improved customer support response time by 60%.\n",
      "- Contributed to developing a high-performance neural network model for financial risk assessment.\n",
      "- Led an engineering team in achieving 99.99% system uptime through infrastructure improvements.\n",
      "- Mentored junior engineers and interns, helping them develop skills and transition into full-time roles.\n",
      "- Designed a visualization dashboard that provided real-time insights into key business metrics.\n",
      "- Collaborated with legal teams to ensure compliance with GDPR and CCPA regulations in AI projects.\n",
      "- Developed an API that streamlined data access across multiple internal services, reducing data retrieval times.\n",
      "- Improved A/B testing methodologies, leading to more accurate product experimentation and decision-making.\n"
     ]
    }
   ],
   "source": [
    "accomplishments = \"\"\"\n",
    "- Led the development and deployment of an AI-powered recommendation system that increased user engagement by 35%.\n",
    "- Spearheaded the migration of legacy systems to a cloud-based infrastructure, reducing operational costs by 20%.\n",
    "- Designed and implemented a real-time fraud detection algorithm, improving security and reducing false positives by 40%.\n",
    "- Published multiple research papers on machine learning and NLP in top-tier conferences such as NeurIPS and ICML.\n",
    "- Successfully managed a cross-functional team of engineers, data scientists, and product managers to deliver a high-impact project ahead of schedule.\n",
    "- Optimized database queries and indexing strategies, reducing query response time by 50%.\n",
    "- Developed and launched a company-wide innovation board, fostering knowledge sharing and increasing engineering velocity.\n",
    "- Contributed to open-source projects in the cybersecurity and machine learning communities, gaining over 10,000 GitHub stars.\n",
    "- Implemented a CI/CD pipeline, reducing deployment times from hours to minutes and improving system reliability.\n",
    "- Conducted in-depth bias analysis on machine learning models, implementing fairness adjustments to ensure ethical AI practices.\n",
    "- Improved search ranking algorithms, increasing click-through rates by 25% through advanced NLP techniques.\n",
    "- Designed and taught a machine learning course, mentoring over 200 students and professionals in AI applications.\n",
    "- Created an automated data pipeline that processed millions of records daily, improving data integrity and accuracy.\n",
    "- Received multiple performance awards for outstanding contributions in engineering and innovation.\n",
    "- Developed a predictive analytics tool that improved customer retention rates by 30%.\n",
    "- Presented at international conferences and industry panels on AI ethics and responsible data practices.\n",
    "- Led security audits and vulnerability assessments, strengthening cybersecurity defenses across the organization.\n",
    "- Designed a scalable architecture for a fintech application, handling millions of transactions per second.\n",
    "- Built a personalized chatbot assistant that improved customer support response time by 60%.\n",
    "- Contributed to developing a high-performance neural network model for financial risk assessment.\n",
    "- Led an engineering team in achieving 99.99% system uptime through infrastructure improvements.\n",
    "- Mentored junior engineers and interns, helping them develop skills and transition into full-time roles.\n",
    "- Designed a visualization dashboard that provided real-time insights into key business metrics.\n",
    "- Collaborated with legal teams to ensure compliance with GDPR and CCPA regulations in AI projects.\n",
    "- Developed an API that streamlined data access across multiple internal services, reducing data retrieval times.\n",
    "- Improved A/B testing methodologies, leading to more accurate product experimentation and decision-making.\n",
    "\"\"\"\n",
    "\n",
    "print(accomplishments)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T18:09:03.854647Z",
     "start_time": "2025-03-14T18:09:03.851561Z"
    }
   },
   "id": "b2b462f5216779f2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 65. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaded the migration of legacy systems to a cloud-based infrastructure, reducing operational costs by 20%. Designed and implemented a real-time fraud detection algorithm, improving security and reducing false positives by 40%. Leading a team of engineers, data scientists, and product managers to deliver a high-impact project ahead of schedule.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "def chunk_text(text, max_tokens=1024, overlap=100):\n",
    "    \"\"\"Splits text into chunks with overlap to maintain coherence.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        chunk = words[start : start + max_tokens]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "        start += max_tokens - overlap  # Overlap ensures context preservation\n",
    "    return chunks\n",
    "\n",
    "def summarize_text(text, max_length=150, min_length=50):\n",
    "    \"\"\"Summarizes long text by chunking and summarizing each part separately.\"\"\"\n",
    "    chunks = chunk_text(text)\n",
    "    summaries = [summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text'] for chunk in chunks]\n",
    "\n",
    "    # Optionally summarize the summaries\n",
    "    final_summary = summarizer(\" \".join(summaries), max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "# Example Usage\n",
    "text = \"Your long text here...\"\n",
    "summary = summarize_text(accomplishments)\n",
    "print(summary)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T18:09:15.821119Z",
     "start_time": "2025-03-14T18:09:03.858800Z"
    }
   },
   "id": "4d5b16f145f998eb"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load Hugging Face's zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T18:16:52.650607Z",
     "start_time": "2025-03-14T18:16:49.241740Z"
    }
   },
   "id": "c218c978c6f57224"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Communication**:\n",
      "- Implemented a feedback system that reduced customer support response time by 40%, improving overall satisfaction ratings.\n",
      "\n",
      "**Customer Focus**:\n",
      "\n",
      "**Influence**:\n",
      "- Delivered a company-wide presentation on AI ethics, engaging over 500 employees and increasing awareness of responsible AI practices.\n",
      "- Developed a machine learning model that improved fraud detection accuracy by 35%, reducing financial losses.\n",
      "- Championed a corporate social responsibility initiative, leading volunteer efforts that impacted over 1,000 community members.\n",
      "- Designed and implemented an automated data pipeline that reduced processing time from 8 hours to 30 minutes.\n",
      "- Exceeded quarterly sales targets by 150% through the development of a new client acquisition strategy.\n",
      "\n",
      "**Job Specific Skills**:\n",
      "\n",
      "**Judgment**:\n",
      "\n",
      "**Lives the Values**:\n",
      "\n",
      "**Problem Solving**:\n",
      "- Analyzed market trends and recommended a strategic pivot that led to a 20% revenue increase in six months.\n",
      "\n",
      "**Results Focus**:\n",
      "\n",
      "**Teamwork**:\n",
      "- Led cross-functional negotiations that secured a $5M investment for an innovation initiative, aligning stakeholders across departments.\n",
      "- Collaborated with engineers, designers, and marketers to successfully launch a new product, achieving a 95% adoption rate within the first month.\n"
     ]
    }
   ],
   "source": [
    "# Define competency categories with descriptions\n",
    "categories = {\n",
    "    \"Communication\": \"Effectively conveys information, actively listens, and fosters understanding among stakeholders.\",\n",
    "    \"Customer Focus\": \"Prioritizes customer needs, delivers high-quality service, and builds strong client relationships.\",\n",
    "    \"Influence\": \"Persuades others, builds consensus, and drives decision-making through strong leadership.\",\n",
    "    \"Job Specific Skills\": \"Demonstrates expertise in technical, industry-specific, or role-based competencies.\",\n",
    "    \"Judgment\": \"Makes sound decisions based on analysis, experience, and strategic thinking.\",\n",
    "    \"Lives the Values\": \"Acts with integrity, follows ethical standards, and represents company values.\",\n",
    "    \"Problem Solving\": \"Identifies challenges, analyzes root causes, and develops effective solutions.\",\n",
    "    \"Results Focus\": \"Drives performance, meets goals, and achieves measurable outcomes.\",\n",
    "    \"Teamwork\": \"Collaborates effectively, fosters inclusion, and contributes to team success.\"\n",
    "}\n",
    "\n",
    "\n",
    "accomplishments = [\n",
    "    # Communication\n",
    "    \"Delivered a company-wide presentation on AI ethics, engaging over 500 employees and increasing awareness of responsible AI practices.\",\n",
    "\n",
    "    # Customer Focus\n",
    "    \"Implemented a feedback system that reduced customer support response time by 40%, improving overall satisfaction ratings.\",\n",
    "\n",
    "    # Influence\n",
    "    \"Led cross-functional negotiations that secured a $5M investment for an innovation initiative, aligning stakeholders across departments.\",\n",
    "\n",
    "    # Job Specific Skills\n",
    "    \"Developed a machine learning model that improved fraud detection accuracy by 35%, reducing financial losses.\",\n",
    "\n",
    "    # Judgment\n",
    "    \"Analyzed market trends and recommended a strategic pivot that led to a 20% revenue increase in six months.\",\n",
    "\n",
    "    # Lives the Values\n",
    "    \"Championed a corporate social responsibility initiative, leading volunteer efforts that impacted over 1,000 community members.\",\n",
    "\n",
    "    # Problem Solving\n",
    "    \"Designed and implemented an automated data pipeline that reduced processing time from 8 hours to 30 minutes.\",\n",
    "\n",
    "    # Results Focus\n",
    "    \"Exceeded quarterly sales targets by 150% through the development of a new client acquisition strategy.\",\n",
    "\n",
    "    # Teamwork\n",
    "    \"Collaborated with engineers, designers, and marketers to successfully launch a new product, achieving a 95% adoption rate within the first month.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Convert category keys into a list for classification\n",
    "category_labels = list(categories.keys())\n",
    "\n",
    "def categorize_accomplishments(accomplishments, labels):\n",
    "    \"\"\"Classifies a list of accomplishments into predefined categories.\"\"\"\n",
    "    categorized_results = {category: [] for category in labels}\n",
    "\n",
    "    for accomplishment in accomplishments:\n",
    "        result = classifier(accomplishment, candidate_labels=labels)\n",
    "        best_category = result['labels'][0]  # Select the most probable category\n",
    "        categorized_results[best_category].append(accomplishment)\n",
    "\n",
    "    return categorized_results\n",
    "\n",
    "# Run classification\n",
    "categorized_accomplishments = categorize_accomplishments(accomplishments, category_labels)\n",
    "\n",
    "# Print categorized results\n",
    "for category, items in categorized_accomplishments.items():\n",
    "    print(f\"\\n**{category}**:\")\n",
    "    for item in items:\n",
    "        print(f\"- {item}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T18:17:09.275446Z",
     "start_time": "2025-03-14T18:17:06.196580Z"
    }
   },
   "id": "53956cd04135c683"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "125a1bffb87759ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
